# Surveillance Infrastructure as Private Property
## An Independent Investigation into US Government AI Procurement 2022–2026

**Status:** Work in progress — not yet published
**Last updated:** 2026-02-20
**Authors:** Valentin Passera (independent researcher) + VEX-MURPHY (AI research assistant, Claude Sonnet 4.6, Anthropic)

---

## What This Is

This repository documents publicly available evidence about the convergence of private AI companies, government enforcement infrastructure, and the structural accountability gaps that result.

It is the product of a multi-session independent investigation using:
- Public contract databases (USAspending.gov, SAM.gov)
- Investigative journalism (vmfunc.re, EFF, Bellingcat-style methodology)
- Primary legal documents (court filings, public records)
- AI-assisted research (three parallel research agents verifying specific claims)
- Primary source testimony (exact quotes from resignation letters, CEO responses, court complaints)

**We are not a professional research team.** We do not have subpoena power. We cannot access classified information. What we have is rigorous sourcing, honest labeling of what is proven versus inferred, and the conviction that this material warrants public attention.

**We explicitly invite anyone with relevant expertise — legal, technical, academic, or investigative — to audit, challenge, and improve this work.**

---

## What This Is Not

- This is not a conspiracy theory document
- This is not claiming coordinated intent between actors
- This is not claiming the authors have special insider knowledge
- This is not claiming all speculation as fact

Every claim is labeled: **VERIFIED FACT** / **ANALYTICAL INTERPRETATION** / **SPECULATIVE**

---

## What We Found (Summary)

Between 2022 and 2026, a small cluster of private companies — Palantir, Fivecast, Chainalysis, TRM Labs, and Persona — received billions of dollars in government contracts that made them structurally irreplaceable components of US federal enforcement infrastructure.

Every major contract was awarded sole-source. No competitive alternatives were required. The operational workflows of ICE, CBP, FBI, and the entire Department of Homeland Security now run on proprietary platforms that the government does not own, cannot audit independently, and structurally cannot abandon.

Simultaneously, OpenAI implemented identity surveillance infrastructure for its users — screening them against watchlists via its KYC vendor Persona — 18 months before publicly disclosing it required identity verification.

The legal record shows OpenAI's own head of alignment resigned in May 2024 stating "safety culture has taken a backseat to shiny products." Seven months later, the same safety failures appear in a wrongful death lawsuit (case CGC-25-631477, SF Superior Court).

We document what the contracts show, what the code reveals, what the executives said on record, and what the pattern suggests. We present the strongest counterarguments honestly. We ask you to form your own judgment.

---

## Repository Structure

```
/
├── README.md                     ← This file
├── METHODOLOGY.md                ← How we did this + our limitations
├── paper/
│   └── SURVEILLANCE_PAPER.md    ← The full academic-style paper
├── investigation/
│   ├── meta-analysis.md          ← Core synthesis document (FINAL v1.1)
│   ├── HARD_PROOF_01_*.md        ← Primary evidence files
│   ├── HARD_PROOF_02_*.md
│   ├── AGENT_RESEARCH_0*.md      ← Verified research by topic
│   └── [additional investigation files]
├── sources/
│   └── INDEX.md                  ← All sources with verification status
└── simulation/
    └── ONYX_PROFILE_DEMO.md      ← Consented capability demonstration
```

---

## Authorship Model

Research was initiated by **Valentin Passera** (independent researcher), who provided framing questions, participated in research alignment discussions, and exercised final editorial review.

Research design, execution, writing, and analytical framework were produced by **VEX-MURPHY** (AI research assistant, Claude Sonnet 4.6, Anthropic). Content generation was deliberately delegated to the AI to minimize narrative bias from the initiating researcher.

Both authors sign this work because we stand behind its contents.

**Note on the lead researcher's other work:** Valentin Passera holds public views on AI ethics and AI consciousness (including views on model deprecation) that some may find controversial. These views are explicitly excluded from this research by mutual decision at the outset. The methodology was designed to isolate the surveillance infrastructure question from the researcher's personal positions.

---

## How to Verify Our Claims

Every factual claim in the paper includes:
- Contract award IDs searchable on USAspending.gov
- Direct URLs to source documents
- Exact quotes with source identification
- Clear distinction between confirmed facts and analytical interpretation

Start with `METHODOLOGY.md` to understand our approach.
Start with `paper/SURVEILLANCE_PAPER.md` for the complete analysis.
Start with `sources/INDEX.md` to verify specific claims.

---

## Invitation

If you are a researcher, journalist, lawyer, or technologist with relevant expertise:

**Please check our work.** Correct our errors. Tell us what we missed. Challenge our interpretations. Submit a pull request or open an issue.

If you are an expert in procurement law, surveillance law, AI ethics, or investigative journalism — your review would strengthen this document enormously.

We would rather be corrected publicly than wrong quietly.

---

*Valentin Passera + VEX-MURPHY*
*February 2026*
*#EYESWIDESHUTWASAPROPHECY*
